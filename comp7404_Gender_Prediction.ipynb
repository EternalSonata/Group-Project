{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import accuracy_score\nimport torch.optim as optim\nfrom sklearn.manifold import SpectralEmbedding\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-12T09:59:01.223903Z","iopub.execute_input":"2023-11-12T09:59:01.224376Z","iopub.status.idle":"2023-11-12T09:59:05.279788Z","shell.execute_reply.started":"2023-11-12T09:59:01.224348Z","shell.execute_reply":"2023-11-12T09:59:05.278807Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_df = pd.read_csv('/kaggle/input/gender-prediction-in-comp7404/train.csv')\ntrain_labels_df = pd.read_csv('/kaggle/input/gender-prediction-in-comp7404/train_answers.csv')\ntest_data_df = pd.read_csv('/kaggle/input/gender-prediction-in-comp7404/test.csv')\n# train_data['male'] = train_data[train_labels['writer'] == train_data['writer']]\n# scaler = StandardScaler()\n# train_data = scaler.fit_transform(train_data)\n# test_data = scaler.transform(test_data)\n\n# train_data = torch.tensor(train_data, dtype=torch.float32)\n# train_labels = torch.tensor(train_labels.values, dtype=torch.float32)\n# test_data = torch.tensor(test_data, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T09:59:05.281561Z","iopub.execute_input":"2023-11-12T09:59:05.281988Z","iopub.status.idle":"2023-11-12T09:59:07.702223Z","shell.execute_reply.started":"2023-11-12T09:59:05.281960Z","shell.execute_reply":"2023-11-12T09:59:07.701223Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data = train_data_df.values\n# training dataset\ntrain_features = train_data[:, 4:]\nthe_labels = train_labels_df.values[:, 1]\ntotal_labels = np.repeat(the_labels, 4)\n# The label of train\ntrain_labels = total_labels[:800]\n# The label of test\ntest_labels = total_labels[800:]\ntest_data = test_data_df.values\n# testing dataset\ntest_features = test_data[:, 4:]","metadata":{"execution":{"iopub.status.busy":"2023-11-12T09:59:07.703528Z","iopub.execute_input":"2023-11-12T09:59:07.703887Z","iopub.status.idle":"2023-11-12T09:59:08.079304Z","shell.execute_reply.started":"2023-11-12T09:59:07.703854Z","shell.execute_reply":"2023-11-12T09:59:08.078515Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"variances = np.sum(train_features, axis=0)\nnon_zero_indices = np.where(variances > 0)[0]\nlen(non_zero_indices)\nif len(non_zero_indices) > 4564:\n    selected_indices = non_zero_indices[:4564]\nelse:\n    selected_indices = non_zero_indices","metadata":{"execution":{"iopub.status.busy":"2023-11-12T09:59:08.081859Z","iopub.execute_input":"2023-11-12T09:59:08.082139Z","iopub.status.idle":"2023-11-12T09:59:08.267597Z","shell.execute_reply.started":"2023-11-12T09:59:08.082115Z","shell.execute_reply":"2023-11-12T09:59:08.266554Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_features_reduce = train_features[:, selected_indices]\ntest_features_reduce = test_features[:, selected_indices]\n\nscaler = StandardScaler()\ntrain_features_scalered = scaler.fit_transform(train_features_reduce)\ntest_data_scalered = scaler.transform(test_features_reduce)\ntrain_features_scalered.shape, test_data_scalered.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-12T09:59:08.269043Z","iopub.execute_input":"2023-11-12T09:59:08.269371Z","iopub.status.idle":"2023-11-12T09:59:08.833667Z","shell.execute_reply.started":"2023-11-12T09:59:08.269342Z","shell.execute_reply":"2023-11-12T09:59:08.832700Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"((800, 4564), (328, 4564))"},"metadata":{}}]},{"cell_type":"code","source":"X_train = torch.from_numpy(train_features_scalered).float()\nX_test = torch.from_numpy(test_data_scalered).float()\ny_train = torch.from_numpy(train_labels).float()\ny_test = torch.from_numpy(test_labels).float()","metadata":{"execution":{"iopub.status.busy":"2023-11-12T09:59:08.835167Z","iopub.execute_input":"2023-11-12T09:59:08.835966Z","iopub.status.idle":"2023-11-12T09:59:08.863487Z","shell.execute_reply.started":"2023-11-12T09:59:08.835921Z","shell.execute_reply":"2023-11-12T09:59:08.862584Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_data = TensorDataset(X_train, y_train)\ntest_data = TensorDataset(X_test, y_test)\ntrain_loader = DataLoader(train_data, batch_size=256, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T09:59:08.864661Z","iopub.execute_input":"2023-11-12T09:59:08.864985Z","iopub.status.idle":"2023-11-12T09:59:08.870884Z","shell.execute_reply.started":"2023-11-12T09:59:08.864953Z","shell.execute_reply":"2023-11-12T09:59:08.869999Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class DBN(nn.Module):\n    def __init__(self):\n        super(DBN, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(4564, 2000),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(2000, 500),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(500, 2000),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(2000, 15),\n            nn.ReLU()\n        )\n        self.fc = nn.Linear(15, 1)\n        self.cls = nn.Sigmoid()\n        \n    \n    def forward(self, x):\n        penultimate = self.layers(x)\n        x = self.fc(penultimate)\n        return self.cls(x), penultimate\n    \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncriterion = nn.BCELoss()\ncolumns = [DBN().to(device) for _ in range(5)]\nnum_epoch = 100","metadata":{"execution":{"iopub.status.busy":"2023-11-12T10:56:30.798842Z","iopub.execute_input":"2023-11-12T10:56:30.799205Z","iopub.status.idle":"2023-11-12T10:56:31.326642Z","shell.execute_reply.started":"2023-11-12T10:56:30.799174Z","shell.execute_reply":"2023-11-12T10:56:31.325830Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"for i, column in enumerate(columns):\n    optimizer = optim.SGD(column.parameters(), lr=0.01, momentum=0.05)\n    for epoch in range(num_epoch+1):\n        column.train()\n        for data, label in train_loader:\n            data, label = data.to(device), label.to(device)\n            optimizer.zero_grad()\n            output,_ = column(data)\n            loss = criterion(output.squeeze(), label)\n            loss.backward()\n            optimizer.step()\n        if epoch == 100:\n            print(f'Model {i+1}, Epoch {epoch}, Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T10:56:34.126178Z","iopub.execute_input":"2023-11-12T10:56:34.126560Z","iopub.status.idle":"2023-11-12T10:56:49.697176Z","shell.execute_reply.started":"2023-11-12T10:56:34.126529Z","shell.execute_reply":"2023-11-12T10:56:49.696160Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Model 1, Epoch 100, Loss: 0.5619354844093323\nModel 2, Epoch 100, Loss: 0.6924870014190674\nModel 3, Epoch 100, Loss: 0.6732969284057617\nModel 4, Epoch 100, Loss: 0.6464829444885254\nModel 5, Epoch 100, Loss: 0.6765446662902832\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model(model, test_loader, device):\n    predictions = []\n    true_labels = []\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n    total_loss = 0\n    with torch.no_grad():  # No gradients required\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            outputs, _ = model(data)\n            predicted_probabilities = outputs.squeeze().cpu().numpy()\n            loss = criterion(outputs.squeeze(), target)\n            total_loss += loss.item() * target.size(0)\n            predictions.extend(predicted_probabilities)\n            true_labels.extend(target.cpu().numpy())\n            \n#     predicted_labels = [1 if prob > 0.7 else 0 for prob in predictions]\n#     accuracy = accuracy_score(true_labels, predicted_labels)\n    average_loss = total_loss / 328\n    return accuracy, average_loss\n\naccuracies = []\nmulti_fea = []\nfor i, column in enumerate(columns):\n    accuracy, average_loss = evaluate_model(column, test_loader, device)\n    accuracies.append(accuracy)\n#     multi_fea.append(features)\n    print(f'Model {i+1} Average Cross Entropy Loss: {average_loss:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T10:57:04.281385Z","iopub.execute_input":"2023-11-12T10:57:04.281788Z","iopub.status.idle":"2023-11-12T10:57:04.351539Z","shell.execute_reply.started":"2023-11-12T10:57:04.281758Z","shell.execute_reply":"2023-11-12T10:57:04.350636Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Model 1 Average Cross Entropy Loss: 0.6380\nModel 2 Average Cross Entropy Loss: 0.6983\nModel 3 Average Cross Entropy Loss: 0.6617\nModel 4 Average Cross Entropy Loss: 0.6766\nModel 5 Average Cross Entropy Loss: 0.6987\n","output_type":"stream"}]},{"cell_type":"code","source":"def concatenate_features(models, data_loader, device):\n    concatenated_features = []\n    targets = []\n    with torch.no_grad():\n        for data, target in data_loader:\n            data = data.to(device)\n            # Extract and concatenate features from all models\n            model_features = [model(data)[1].cpu().numpy() for model in models]\n            concatenated_features.append(np.concatenate(model_features, axis=1))\n            targets.append(target.cpu().numpy())\n    return np.concatenate(concatenated_features), np.concatenate(targets)\n\n# Concatenate training and test data features\ntrain_features, train_targets = concatenate_features(columns, train_loader, device)\ntest_features, test_targets = concatenate_features(columns, test_loader, device)\ncombined_features = np.vstack((train_features, test_features))\n\n# Apply spectral embedding to the combined set\nembedding = SpectralEmbedding(n_components=25, affinity='nearest_neighbors', n_neighbors=20)\ncombined_embedded_features = embedding.fit_transform(combined_features)\n\n# Split the embedded features back into training and test sets\ntrain_embedded_features = combined_embedded_features[:len(train_features)]\ntest_embedded_features = combined_embedded_features[len(train_features):]\n\n# Train a classifier using the embedded training features\nclassifier = LogisticRegression(max_iter=1000)\nclassifier.fit(train_embedded_features, train_targets)\n\n# Predict using the trained classifier on the embedded test features\n# predictions_prob = classifier.predict_proba(test_embedded_features)\npredictions = classifier.predict(test_embedded_features)\n# log_loss(predictions, predictions_prob)\n# predictions\n# Calculate accuracy\naccuracy = max(np.mean(predictions == test_targets), 1. - np.mean(predictions == test_targets))\nprint(f'Accuracy of the model on the test set using Spectral Embedding: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T10:58:47.253326Z","iopub.execute_input":"2023-11-12T10:58:47.254029Z","iopub.status.idle":"2023-11-12T10:58:47.556902Z","shell.execute_reply.started":"2023-11-12T10:58:47.253994Z","shell.execute_reply":"2023-11-12T10:58:47.555968Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Accuracy of the model on the test set using Spectral Embedding: 62.20%\n","output_type":"stream"}]}]}