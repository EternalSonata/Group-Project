{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Subset\nimport numpy as np\nimport torch.nn.functional as F\nfrom scipy.sparse import csgraph\nfrom scipy.optimize import minimize\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.manifold import SpectralEmbedding\nfrom sklearn.neighbors import kneighbors_graph\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics.pairwise import rbf_kernel\nfrom scipy.sparse.csgraph import laplacian as csgraph_laplacian\nfrom sklearn.metrics.pairwise import euclidean_distances\nfrom scipy.sparse import csr_matrix\nfrom scipy.sparse.linalg import eigsh\nfrom scipy.sparse import diags\nfrom numpy.linalg import eig\nfrom numpy.linalg import eigh\nfrom scipy.linalg import block_diag\nfrom sklearn.preprocessing import normalize\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import TruncatedSVD","metadata":{"execution":{"iopub.status.busy":"2023-11-12T11:03:28.116037Z","iopub.execute_input":"2023-11-12T11:03:28.116452Z","iopub.status.idle":"2023-11-12T11:03:32.684121Z","shell.execute_reply.started":"2023-11-12T11:03:28.116408Z","shell.execute_reply":"2023-11-12T11:03:32.683218Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the CNN architecture with specified layers\nclass CustomCNN(nn.Module):\n    def __init__(self):\n        super(CustomCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 100, kernel_size=5)\n        self.conv2 = nn.Conv2d(100, 150, kernel_size=5)\n        self.conv3 = nn.Conv2d(150, 200, kernel_size=3)\n        self.mp = nn.MaxPool2d(2)\n        self.fc1 = nn.Linear(200 * 2 * 2, 300)  # Assuming the feature map size is 2x2\n        self.fc2 = nn.Linear(300, 10)\n\n    def forward(self, x):\n        x = self.mp(F.relu(self.conv1(x)))\n        x = self.mp(F.relu(self.conv2(x)))\n        x = F.relu(self.conv3(x))\n        x = x.view(-1, 200 * 2 * 2)  # Flatten the tensor for the fully connected layer\n        penultimate = F.relu(self.fc1(x))\n        x = self.fc2(penultimate)\n        return F.log_softmax(x, dim=1), penultimate\n\n# Data preparation\n# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\nindices = np.hstack([np.where(train_dataset.targets == i)[0][:100] for i in range(10)])\nsubset_train_dataset = Subset(train_dataset, indices)\ntrain_loader = DataLoader(subset_train_dataset, batch_size=64, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n\n# Initialize and train 5 separate CNNs\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodels = [CustomCNN().to(device) for _ in range(5)]\ncriterion = nn.CrossEntropyLoss()\n\nmodel_features = {i: [] for i in range(len(models))}\n\nfor i, model in enumerate(models):\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n\n    # Training loop\n    for epoch in range(1, 101):  # 100 epochs\n        model.train()\n        model_features[i].clear()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output, penultimate = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            model_features[i].append(penultimate.detach().cpu().numpy())\n        scheduler.step()  # Anneal the learning rate\n        if epoch == 100:\n            print(f'Model {i+1}, Epoch {epoch}, Loss: {loss.item()}')\n    model_features[i] = np.concatenate(model_features[i], axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T11:03:32.686318Z","iopub.execute_input":"2023-11-12T11:03:32.686940Z","iopub.status.idle":"2023-11-12T11:05:03.552939Z","shell.execute_reply.started":"2023-11-12T11:03:32.686905Z","shell.execute_reply":"2023-11-12T11:05:03.551941Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 136722630.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 44274741.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 31839947.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 23665253.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nModel 1, Epoch 100, Loss: 0.11837957054376602\nModel 2, Epoch 100, Loss: 0.11553546041250229\nModel 3, Epoch 100, Loss: 0.1151246577501297\nModel 4, Epoch 100, Loss: 0.14135919511318207\nModel 5, Epoch 100, Loss: 0.12834122776985168\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model(model, test_loader, device):\n    features, test_targets = [], []\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n    with torch.no_grad():  # No gradients required\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            outputs, penultimate = model(data)\n            _, predicted = torch.max(outputs.data, 1)  # Get the index of the max log-probability\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n            features.append(penultimate.cpu().numpy())\n            test_targets.append(target.cpu().numpy())\n            \n    accuracy = correct / total\n    features = np.concatenate(features, axis=0)\n    test_targets = np.concatenate(test_targets, axis=0)\n    return accuracy, features, test_targets\n\naccuracies = []\nmulti_fea = []\nfor i, model in enumerate(models):\n    accuracy, features, test_targets = evaluate_model(model, test_loader, device)\n    accuracies.append(accuracy)\n    multi_fea.append(features)\n    print(f'Model {i+1} Accuracy: {accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T11:05:03.554256Z","iopub.execute_input":"2023-11-12T11:05:03.554628Z","iopub.status.idle":"2023-11-12T11:05:09.324321Z","shell.execute_reply.started":"2023-11-12T11:05:03.554593Z","shell.execute_reply":"2023-11-12T11:05:09.323370Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Model 1 Accuracy: 92.26%\nModel 2 Accuracy: 92.68%\nModel 3 Accuracy: 92.15%\nModel 4 Accuracy: 92.06%\nModel 5 Accuracy: 92.08%\n","output_type":"stream"}]},{"cell_type":"code","source":"# n_components = 10  # Number of desired dimensions\n# svd_model = TruncatedSVD(n_components=n_components)\n# svd_features_train = svd_model.fit_transform(np.concatenate(list(model_features.values()), axis=-1))\n\n# # Train a classifier using the SVD-reduced training features\n# classifier = LogisticRegression(max_iter=5000)\n# classifier.fit(svd_features_train, train_dataset.targets[indices].numpy())\n\n# # Function to evaluate the model using the Truncated SVD on test data\n# def evaluate_with_svd(models, test_loader, classifier, device, svd_model):\n#     test_features = []\n#     test_targets = []\n#     with torch.no_grad():\n#         for data, target in test_loader:\n#             data = data.to(device)\n#             # Extract features from all models and concatenate them\n#             concatenated_features = np.concatenate([model(data)[1].cpu().numpy() for model in models], axis=-1)\n#             print(concatenated_features.shape)\n#             test_features.append(concatenated_features)\n#             test_targets.append(target.cpu().numpy())\n    \n#     # Apply Truncated SVD to the concatenated test features\n#     test_features = np.concatenate(test_features, axis=0)\n#     print(test_features.shape)\n#     svd_test_features = svd_model.transform(test_features)  # Transform using the fitted SVD model\n    \n#     # Predict using the trained classifier\n#     predictions = classifier.predict(svd_test_features)\n#     test_targets = np.concatenate(test_targets, axis=0)\n    \n#     # Calculate accuracy\n#     accuracy = np.mean(predictions == test_targets)\n#     return accuracy\n\n# # Evaluate the classifier with the test set\n# test_accuracy = evaluate_with_svd(models, test_loader, classifier, device, svd_model)\n# print(f'Test Accuracy: {test_accuracy * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T11:05:09.326384Z","iopub.execute_input":"2023-11-12T11:05:09.326709Z","iopub.status.idle":"2023-11-12T11:05:12.033542Z","shell.execute_reply.started":"2023-11-12T11:05:09.326682Z","shell.execute_reply":"2023-11-12T11:05:12.032364Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(1000, 1500)\n(1000, 1500)\n(1000, 1500)\n(1000, 1500)\n(1000, 1500)\n(1000, 1500)\n(1000, 1500)\n(1000, 1500)\n(1000, 1500)\n(1000, 1500)\n(10000, 1500)\nTest Accuracy: 91.62%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to concatenate features from all models\ndef concatenate_features(models, data_loader, device):\n    concatenated_features = []\n    targets = []\n    with torch.no_grad():\n        for data, target in data_loader:\n            data = data.to(device)\n            # Extract and concatenate features from all models\n            model_features = [model(data)[1].cpu().numpy() for model in models]\n            concatenated_features.append(np.concatenate(model_features, axis=1))\n            targets.append(target.cpu().numpy())\n    return np.concatenate(concatenated_features), np.concatenate(targets)\n\n# Concatenate training and test data features\ntrain_features, train_targets = concatenate_features(models, train_loader, device)\ntest_features, test_targets = concatenate_features(models, test_loader, device)\ncombined_features = np.vstack((train_features, test_features))\n\n# Apply spectral embedding to the combined set\nembedding = SpectralEmbedding(n_components=10, affinity='nearest_neighbors', n_neighbors=5)\ncombined_embedded_features = embedding.fit_transform(combined_features)\n\n# Split the embedded features back into training and test sets\ntrain_embedded_features = combined_embedded_features[:len(train_features)]\ntest_embedded_features = combined_embedded_features[len(train_features):]\n\n# Train a classifier using the embedded training features\nclassifier = LogisticRegression(max_iter=1000)\nclassifier.fit(train_embedded_features, train_targets)\n\n# Predict using the trained classifier on the embedded test features\npredictions = classifier.predict(test_embedded_features)\n\n# Calculate accuracy\naccuracy = np.mean(predictions == test_targets)\nprint(f'Accuracy of the model on the test set using Spectral Embedding: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-12T11:05:12.035063Z","iopub.execute_input":"2023-11-12T11:05:12.035776Z","iopub.status.idle":"2023-11-12T11:05:21.527325Z","shell.execute_reply.started":"2023-11-12T11:05:12.035738Z","shell.execute_reply":"2023-11-12T11:05:21.526295Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Accuracy of the model on the test set using Spectral Embedding: 94.02%\n","output_type":"stream"}]},{"cell_type":"code","source":"# def global_coordinate_alignment(part_embeddings, n_components, r):\n#     # Number of views\n#     m = len(part_embeddings)\n#     # Total number of samples\n#     n_samples = part_embeddings[0].shape[0]\n    \n#     # Initialize global embedding Y and weights alpha\n#     Y_global_init = np.random.rand(n_samples, n_components)\n#     alphas_init = np.full(m, 1 / m)\n\n#     # Flatten the initial global embedding and concatenate with weights\n#     x0 = np.concatenate([Y_global_init.flatten(), alphas_init], axis=0)\n\n#     # Define the objective function\n#     def objective(x):\n#         # Extract Y and alphas from the flattened vector\n#         Y = x[:-m].reshape(n_samples, n_components)\n#         alphas = x[-m:]\n        \n#         # Compute the objective function value\n#         loss = 0\n#         for i, Y_i in enumerate(part_embeddings):\n#             L_i = compute_graph_laplacian(Y_i)  \n#             loss += alphas[i]**r * np.trace(np.dot(Y.T, np.dot(L_i, Y)))\n#         return loss\n\n#     # Define the constraint for alpha (they should sum to 1)\n#     def constraint_alpha(x):\n#         return np.sum(x[-m:]) - 1\n\n#     # Define the constraints for the optimization\n#     cons = ({'type': 'eq', 'fun': constraint_alpha})\n\n#     # Perform the optimization\n#     result = minimize(\n#         fun=objective,\n#         x0=x0,\n#         constraints=cons,\n#         method='SLSQP',  # Sequential Least Squares Programming\n#         options={'disp': True}\n#     )\n\n#     # Extract the optimized Y and alphas from the result\n#     Y_global_optimized = result.x[:-m].reshape(n_samples, n_components)\n#     alphas_optimized = result.x[-m:]\n    \n#     return Y_global_optimized, normalize(alphas_optimized.reshape(1, -1), norm='l1').flatten()\n\n# # This function needs to be implemented\n# def compute_graph_laplacian(Y_i):\n#     connectivity = kneighbors_graph(Y_i, n_neighbors=20, include_self=True)\n#     laplacian_matrix = csgraph_laplacian(connectivity, normed=True)\n#     return laplacian_matrix\n\n# # Part embeddings from different views/models would be used as input for this function\n# # part_embeddings = [...]\n# # Assuming n_components and r are defined\n# # Y_global, alphas = global_coordinate_alignment(part_embeddings, n_components, r)\n# multi_features = []\n# for i in range(5):\n#     multi_features.append(model_features[i])\n# global_coordinate_alignment(multi_features, 9, 1.5)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T11:05:21.528902Z","iopub.execute_input":"2023-11-12T11:05:21.529227Z","iopub.status.idle":"2023-11-12T11:05:21.535105Z","shell.execute_reply.started":"2023-11-12T11:05:21.529200Z","shell.execute_reply":"2023-11-12T11:05:21.534099Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# from scipy.optimize import minimize\n# from scipy.sparse import diags\n\n# # Let's assume we have part_embeddings which is a list of numpy arrays,\n# # each containing the part-based low-dimensional embeddings for different views.\n\n# # Initialize the global embedding Y and the weights alpha for each view\n# Y_global_init = np.random.rand(d, n)  # d is the target dimensionality, n is the number of data points\n# alphas = np.full(len(part_embeddings), 1 / len(part_embeddings))  # Start with uniform weights\n\n# # Define the objective function for global coordinate alignment\n# def global_alignment_objective(Y_global, part_embeddings, alphas, r):\n#     Y_global = Y_global.reshape(d, n)\n#     objective = 0\n#     for Y_part, alpha in zip(part_embeddings, alphas):\n#         # Compute the weighted trace of Y_part's graph Laplacian and Y_global\n#         L_part = compute_graph_laplacian(Y_part)  # You need to implement this based on the paper\n#         objective += alpha**r * np.trace(Y_global.T @ L_part @ Y_global)\n#     return objective\n\n# # Define the constraint for the optimization: YY^T = I\n# def orthogonality_constraint(Y_global):\n#     Y_global = Y_global.reshape(d, n)\n#     return np.dot(Y_global, Y_global.T) - np.eye(d)\n\n# # Flatten Y_global for scipy's optimizer\n# Y_global_flattened = Y_global_init.flatten()\n\n# # Run the optimization\n# result = minimize(\n#     fun=global_alignment_objective,\n#     x0=Y_global_flattened,\n#     args=(part_embeddings, alphas, r),\n#     constraints={'type': 'eq', 'fun': orthogonality_constraint},\n#     method='SLSQP',  # Sequential Least Squares Programming\n#     options={'disp': True}\n# )\n\n# # Reshape the result back to the matrix form\n# Y_global_optimized = result.x.reshape(d, n)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T11:05:21.536199Z","iopub.execute_input":"2023-11-12T11:05:21.536507Z","iopub.status.idle":"2023-11-12T11:05:21.551819Z","shell.execute_reply.started":"2023-11-12T11:05:21.536433Z","shell.execute_reply":"2023-11-12T11:05:21.550896Z"},"trusted":true},"execution_count":7,"outputs":[]}]}